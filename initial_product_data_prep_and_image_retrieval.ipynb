{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wget\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source: http://deepyeti.ucsd.edu/jianmo/amazon/index.html\n",
    "product_url = 'http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles/meta_Clothing_Shoes_and_Jewelry.json.gz'\n",
    "filename = wget.download(product_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "data = []\n",
    "with gzip.open('meta_Clothing_Shoes_and_Jewelry.json.gz') as f:\n",
    "   for l in f:\n",
    "       item = l.strip().decode(\"utf-8\")\n",
    "       data.append(json.loads(item))\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Remove duplicates - keep last\n",
    "df.drop_duplicates(subset='title', keep='last', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific filtering for training data\n",
    "\n",
    "# Some code is embeded in the title column for several rows. Identify rows where the\n",
    "# count is very high\n",
    "df['title_length'] = df['title'].str.len()\n",
    "\n",
    "# Filter df for those with count less than 50000\n",
    "df = df[df['title_length'] < 50000]\n",
    "\n",
    "# List of columns that must have a value for the product to be included\n",
    "key_cols = ['asin', 'title', 'brand', 'description', 'image', 'feature', 'category', 'similar_item']\n",
    "\n",
    "# Count non-NaN values across key columns\n",
    "df['count'] = df[key_cols].count(axis=1)\n",
    "\n",
    "# Filter df and select columns of interest\n",
    "df = df[df['count'] >= 8]\n",
    "df = df[key_cols + ['also_buy', 'also_view']]\n",
    "\n",
    "# Identify products with 'women' or 'men' in title (used to )\n",
    "df = df[df['adj_title'].str.contains('women| men')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to clean title\n",
    "def remove_num_and_empty_strings(lst):\n",
    "   return [s for s in lst if (not any(map(str.isdigit, s))) & (len(s) != 0)]\n",
    "\n",
    "def clean_title(row):\n",
    "    title, brand = row[['title', 'brand']]\n",
    "    adj_title = re.sub('[^a-zA-Z\\d\\s:]', '', title.lower())\n",
    "    title_tokens = remove_num_and_empty_strings(adj_title.split(' '))\n",
    "    brand_tokens = brand.lower().split(' ')\n",
    "    adj_title_tokens = list(set(title_tokens) - set(brand_tokens))\n",
    "    adj_title = ' '.join(adj_title_tokens)\n",
    "    return adj_title\n",
    "\n",
    "# Clean title\n",
    "df['adj_title'] = df.apply(clean_title, axis=1)\n",
    "\n",
    "# Clean brand\n",
    "df['adj_brand'] = df['brand'].apply(lambda x: re.sub('\\s', '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean category\n",
    "def filter_category(ctgy):\n",
    "    ctgy = list(chain.from_iterable(list(ctgy)))\n",
    "    ctgy = [item.split(' ') for item in ctgy]\n",
    "    filt_ctgy = [''.join(item) for item in ctgy if ('&' in item) | (len(item)==1)]\n",
    "    return [item.lower() for item in filt_ctgy]\n",
    "    \n",
    "df['category_filt'] = df[['category']].apply(filter_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ids of similar items\n",
    "df['similar_item_ids'] = df['similar_item']. \\\n",
    "    apply(lambda items: [items[i]['asin'] for i in range(len(items)) if items[i]['asin'] != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels for images\n",
    "\n",
    "def detect_labels(uri):\n",
    "    \n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the Web.\"\"\"\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    # Performs label detection on the image file\n",
    "    response = client.label_detection(image=image)  \n",
    "\n",
    "    # Convert the response to dictionary\n",
    "    resp_dict = MessageToDict(response)\n",
    "    \n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    # Extract annotations\n",
    "    annotations = resp_dict['labelAnnotations']\n",
    "    \n",
    "    # Extract descriptions\n",
    "    labels = [re.sub('\\s', '', annotations[i]['description'].lower()) for i in range(len(annotations))]\n",
    "\n",
    "    return labels\n",
    "\n",
    "images = df['image'].tolist()\n",
    "images = [item for sublist in images for item in sublist]\n",
    "image_count = len(images)\n",
    "\n",
    "def clean_uri_and_retrieve_labels(uri):\n",
    "    index = images.index(uri)\n",
    "    remaining = image_count - index\n",
    "    percent_complete = round(index / image_count * 100, 2)\n",
    "    hours_left = remaining / 8 / 60\n",
    "    delta = timedelta(hours=hours_left)\n",
    "    estimated_completion = datetime.now() + delta\n",
    "    print('\\nWorking on image', index, 'of', image_count, '.', \n",
    "          percent_complete, '% complete. At 8 responses',\n",
    "          'per minute, completion in', hours_left, 'hours.',\n",
    "          'Estimated completion: ', estimated_completion)\n",
    "    clean_uri = re.sub('[_].+[_.]', '', uri)\n",
    "    print(\"Cleaned uri is: \", clean_uri)\n",
    "    try:\n",
    "        labels = detect_labels(clean_uri)\n",
    "        print(\"Successfully processed uri:\", uri)\n",
    "        return labels\n",
    "    except:\n",
    "        print(\"****WARNING: Could not process uri: \", uri)\n",
    "        return [\"\"]\n",
    "        \n",
    "def label_images(uris):\n",
    "    if isinstance(uris, str):\n",
    "        return clean_uri_and_retrieve_labels(uris)\n",
    "    else:\n",
    "        labels = [clean_uri_and_retrieve_labels(uri) for uri in uris]\n",
    "        return list(set([item for sublist in labels for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve image labels - this will be lengthy process (~8 images per minute). Also, you must have\n",
    "# access to the Google Cloud Vision API: https://cloud.google.com/vision/docs/quickstart-client-libraries\n",
    "# Bulk processing is also available, but not utilized here.\n",
    "df['image_labels'] = df['image'].apply(label_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "print(df[['adj_title', 'image_labels']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine adj_title, adj_brand, category_filt, and image_labels into 'document' (sentence)\n",
    "\n",
    "# Recursive flattening of lists\n",
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])\n",
    "\n",
    "# Create set from list (to remove duplicates) and join into single string\n",
    "def concat_descrip(S):\n",
    "    lst = flatten(list(S))\n",
    "    words = flatten([w.split(' ') for w in lst])\n",
    "    return ' '.join(list(set(words)))\n",
    "\n",
    "df['document'] = df[['adj_title', 'adj_brand', 'category_filt', 'image_labels']].apply(concat_descrip, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and save\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "# Check first row\n",
    "print(df.iloc[0])\n",
    "\n",
    "# Save data\n",
    "df.to_pickle(\"df_with_image_labels.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
